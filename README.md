# ğŸ›¡ï¸ YouTube Hate Speech Detector

<div align="center">

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-1.0.0-green.svg)
![React](https://img.shields.io/badge/React-18.3.1-61DAFB.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Tests](https://img.shields.io/badge/tests-49%20passing-success.svg)
![Coverage](https://img.shields.io/badge/coverage-comprehensive-brightgreen.svg)

**Sistema de detecciÃ³n automÃ¡tica de mensajes de odio en comentarios de YouTube usando NLP y Deep Learning con DistilBERT**

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢ [Demo en Vivo](#-demo-en-vivo) â€¢ [InstalaciÃ³n](#-instalaciÃ³n) â€¢ [API](#-api-endpoints) â€¢ [MÃ©tricas](#-mÃ©tricas-del-modelo)

</div>

---

## ğŸ“‹ DescripciÃ³n

YouTube enfrenta un aumento significativo en mensajes de odio entre los comentarios de sus vÃ­deos. Este proyecto desarrolla una soluciÃ³n automatizada de detecciÃ³n usando **Procesamiento del Lenguaje Natural (NLP)** y **Deep Learning** con transformers (DistilBERT) para identificar y clasificar estos mensajes con alta precisiÃ³n, permitiendo acciones de moderaciÃ³n escalables.

### ğŸ¯ Problema
- Volumen masivo de comentarios imposible de moderar manualmente (miles por minuto)
- Costos prohibitivos de equipos de moderaciÃ³n humana 24/7
- Necesidad de escalabilidad y detecciÃ³n en tiempo real
- Falsos positivos que afectan la experiencia del usuario

### âœ¨ SoluciÃ³n
API REST robusta con frontend interactivo que analiza texto individual o videos completos de YouTube, detectando hate speech con **85.3% de precisiÃ³n** usando DistilBERT fine-tuned y solo **5.3% de overfitting**.

---

## ğŸŒ Demo en Vivo

### ğŸš€ Backend API (ProducciÃ³n)
- **URL Base**: https://youtube-hate-speech-detector.onrender.com
- **DocumentaciÃ³n Interactiva (Swagger)**: https://youtube-hate-speech-detector.onrender.com/docs
- **Health Check**: https://youtube-hate-speech-detector.onrender.com/health

### ğŸ’» Frontend Local
El frontend React estÃ¡ disponible para ejecuciÃ³n local (instrucciones en [InstalaciÃ³n](#-instalaciÃ³n)).

**CaracterÃ­sticas del Frontend:**
- ğŸ¬ AnÃ¡lisis de videos completos de YouTube (hasta 200 comentarios)
- ğŸ“ PredicciÃ³n de texto individual en tiempo real
- ğŸ“Š VisualizaciÃ³n de mÃ©tricas del modelo (88% accuracy badge)
- ğŸ¨ UI moderna con Tailwind CSS y animaciones
- ğŸ”¥ Botones de ejemplo para testing rÃ¡pido
- ğŸ“ˆ GrÃ¡ficas de toxicidad con cÃ³digo de colores

---

## ğŸš€ CaracterÃ­sticas

### âœ… Completamente Implementado

#### ğŸ¤– Machine Learning & NLP
- âœ… **Modelo DistilBERT fine-tuned** (85.3% accuracy, 83.9% F1-score)
- âœ… **Modelo Logistic Regression** optimizado como baseline (52.5% accuracy)
- âœ… **Preprocesamiento NLP** avanzado (NLTK + Spacy)
  - TokenizaciÃ³n, stemming (PorterStemmer), lemmatization
  - Stopwords removal, limpieza de URLs/menciones
  - NormalizaciÃ³n de texto y vectorizaciÃ³n TF-IDF
- âœ… **Data Augmentation** con NLPAUG (2x dataset â†’ 1,994 samples)
- âœ… **Threshold optimization** para balance precision/recall

#### ğŸŒ Backend & API
- âœ… **FastAPI 1.0.0** con 9 endpoints RESTful
- âœ… **AnÃ¡lisis de videos de YouTube** (YouTube Data API v3)
  - ExtracciÃ³n de hasta 200 comentarios por video
  - Top 10 comentarios tÃ³xicos rankeados por confianza
  - Metadata completa (autor, fecha, video title)
- âœ… **PredicciÃ³n individual y por lotes** (hasta 100 textos)
- âœ… **ComparaciÃ³n de modelos** (LR vs DistilBERT)
- âœ… **Endpoints de estadÃ­sticas y health check**
- âœ… **CORS configurado** para desarrollo flexible

#### âš›ï¸ Frontend
- âœ… **React 18.3.1 + Vite 5.4.2** (desarrollo ultrarrÃ¡pido)
- âœ… **Tailwind CSS 3.4.19** (diseÃ±o responsive y moderno)
- âœ… **Componentes interactivos**:
  - `VideoAnalyzer`: Input de URL, slider de comentarios, resultados con grÃ¡ficas
  - `TextPredictor`: AnÃ¡lisis instantÃ¡neo con confidence scores
- âœ… **MÃ©tricas en vivo**: Display de accuracy, F1, parÃ¡metros, overfitting
- âœ… **Ejemplos pre-cargados**: Videos populares y textos de prueba
- âœ… **Animaciones fluidas**: Spinners, progress bars, fade-in effects

#### ğŸ³ DevOps & Testing
- âœ… **Docker** multi-stage (producciÃ³n + desarrollo)
- âœ… **docker-compose** con hot-reload para dev
- âœ… **49 tests** unitarios (pytest) con cobertura comprehensive
  - 17 tests de preprocessing
  - 18 tests de modelos
  - 14 tests de endpoints API
- âœ… **Deployment en Render** (backend en producciÃ³n)

#### ğŸ“Š AnÃ¡lisis & ExperimentaciÃ³n
- âœ… **4 Jupyter Notebooks** completos:
  - EDA (Exploratory Data Analysis)
  - Preprocessing y modelos clÃ¡sicos
  - DistilBERT con augmentation (NLPAUG)
  - Ensemble con XGBoost
- âœ… **Git LFS** para modelos grandes (255MB DistilBERT)

### ğŸ—ºï¸ Roadmap Futuro
- ğŸ“‹ **MLflow** para tracking de experimentos
- ğŸ“‹ **Base de datos SQLite** para persistencia de predicciones
- ğŸ“‹ **Monitoreo en tiempo real** de streams de comentarios
- ğŸ“‹ **Dashboard analÃ­tico** con Plotly/Streamlit
- ğŸ“‹ **Frontend deployment** en Vercel/Netlify

---

## ğŸ› ï¸ TecnologÃ­as

### Core Stack
| CategorÃ­a | TecnologÃ­as |
|-----------|-------------|
| **Backend** | FastAPI 1.0.0, Uvicorn, Pydantic |
| **ML/DL** | PyTorch 2.0+, Transformers 4.30+ (Hugging Face), Scikit-learn |
| **NLP** | NLTK, Spacy (en_core_web_sm), NLPAUG |
| **Frontend** | React 18.3.1, Vite 5.4.2, Tailwind CSS 3.4.19, Axios 1.7.2 |
| **YouTube** | google-api-python-client (YouTube Data API v3) |
| **Data** | Pandas, NumPy |
| **OptimizaciÃ³n** | Optuna (hyperparameter tuning) |
| **DevOps** | Docker, docker-compose, Render |
| **Testing** | pytest, pytest-cov, httpx |

### Modelos
| Modelo | Accuracy | F1-Score | Overfitting | Estado |
|--------|----------|----------|-------------|--------|
| **DistilBERT** (fine-tuned) | **85.3%** | **83.9%** | **5.3%** | ğŸŸ¢ ProducciÃ³n |
| Logistic Regression | 52.5% | 65.7% | 23.1% | ğŸŸ¡ Baseline |

---

## ğŸ“¦ InstalaciÃ³n

### Requisitos Previos
- Python 3.10+
- Node.js 18+ y npm (para frontend)
- Docker (opcional pero recomendado)
- Git y Git LFS (para clonar modelos grandes)
- YouTube Data API Key (para anÃ¡lisis de videos)

### OpciÃ³n 1: Docker (Recomendado)

```bash
# Clonar repositorio
git clone https://github.com/Bootcamp-IA-P5/ProyectX-NLP-Kiru.git
cd ProyectX-NLP-Kiru

# Instalar Git LFS y descargar modelos
git lfs install
git lfs pull

# Configurar API key de YouTube
cp .env.example .env
# Editar .env y agregar: YOUTUBE_API_KEY=tu_api_key_aqui

# Ejecutar con Docker Compose
docker-compose up --build

# Solo backend producciÃ³n (puerto 8000)
docker-compose up nlp-backend

# Backend desarrollo con hot-reload (puerto 8001)
docker-compose up nlp-dev
```

### OpciÃ³n 2: Local (Desarrollo)

```bash
# Clonar repositorio
git clone https://github.com/Bootcamp-IA-P5/ProyectX-NLP-Kiru.git
cd ProyectX-NLP-Kiru

# Backend Setup
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm

# Configurar variables de entorno
export YOUTUBE_API_KEY=tu_api_key_aqui  # Linux/Mac
# set YOUTUBE_API_KEY=tu_api_key_aqui  # Windows

# Ejecutar backend
uvicorn backend.api.main:app --reload --port 8001

# Frontend Setup (nueva terminal)
cd frontend
npm install
npm run dev  # Corre en http://localhost:5173
```

### URLs de Acceso
- **Backend API**: `http://localhost:8001` (dev) o `http://localhost:8000` (prod)
- **DocumentaciÃ³n Swagger**: `http://localhost:8001/docs`
- **Frontend**: `http://localhost:5173`

---

## ğŸ”Œ API Endpoints

### General

#### `GET /`
**DescripciÃ³n**: InformaciÃ³n de la API y modelos disponibles  
**Response**:
```json
{
  "message": "YouTube Hate Speech Detector API",
  "version": "1.0.0",
  "models_available": ["logistic_regression", "distilbert"],
  "endpoints": ["/predict", "/predict/transformer", "/analyze/video", ...],
  "docs": "/docs"
}
```

#### `GET /health`
**DescripciÃ³n**: Health check del sistema y estado de modelos  
**Response**:
```json
{
  "status": "healthy",
  "timestamp": "2024-12-11T10:30:00",
  "models_loaded": {
    "logistic_regression": true,
    "distilbert": true
  },
  "youtube_api": "configured"
}
```

#### `GET /stats`
**DescripciÃ³n**: EstadÃ­sticas de uso de la API  
**Response**:
```json
{
  "total_predictions_lr": 1250,
  "total_predictions_bert": 3840,
  "total_comparisons": 120,
  "uptime_seconds": 86400
}
```

---

### Predicciones

#### `POST /predict`
**DescripciÃ³n**: PredicciÃ³n con Logistic Regression (baseline)  
**Request Body**:
```json
{
  "text": "I hate this stupid video and everyone who likes it"
}
```
**Response**:
```json
{
  "text": "I hate this stupid video and everyone who likes it",
  "prediction": "hate_speech",
  "confidence": 0.872,
  "model": "logistic_regression_threshold_0.3",
  "timestamp": "2024-12-11T10:35:00"
}
```

#### `POST /predict/transformer`
**DescripciÃ³n**: PredicciÃ³n con DistilBERT (recomendado) â­  
**Request Body**:
```json
{
  "text": "This is amazing! Great content, keep it up!"
}
```
**Response**:
```json
{
  "text": "This is amazing! Great content, keep it up!",
  "prediction": "normal",
  "confidence": 0.945,
  "probabilities": {
    "hate_speech": 0.055,
    "normal": 0.945
  },
  "model": "distilbert-base-uncased-finetuned",
  "timestamp": "2024-12-11T10:36:00"
}
```

#### `POST /predict/batch`
**DescripciÃ³n**: PredicciÃ³n por lotes (hasta 100 textos)  
**Request Body**:
```json
{
  "texts": [
    "Great video!",
    "This sucks, you are terrible",
    "Thanks for sharing this"
  ]
}
```
**Response**:
```json
{
  "predictions": [
    {
      "text": "Great video!",
      "prediction": "normal",
      "confidence": 0.921
    },
    {
      "text": "This sucks, you are terrible",
      "prediction": "hate_speech",
      "confidence": 0.784
    },
    {
      "text": "Thanks for sharing this",
      "prediction": "normal",
      "confidence": 0.956
    }
  ],
  "total_processed": 3,
  "model": "logistic_regression",
  "processing_time_seconds": 0.045
}
```

#### `POST /predict/compare`
**DescripciÃ³n**: Compara predicciones de ambos modelos  
**Request Body**:
```json
{
  "text": "You are so dumb and worthless"
}
```
**Response**:
```json
{
  "text": "You are so dumb and worthless",
  "logistic_regression": {
    "prediction": "hate_speech",
    "confidence": 0.815
  },
  "distilbert": {
    "prediction": "hate_speech",
    "confidence": 0.923,
    "probabilities": {
      "hate_speech": 0.923,
      "normal": 0.077
    }
  },
  "agreement": true,
  "confidence_difference": 0.108
}
```

---

### YouTube Analysis

#### `POST /analyze/video` â­
**DescripciÃ³n**: Analiza comentarios de un video de YouTube  
**Request Body**:
```json
{
  "url": "https://www.youtube.com/watch?v=9bZkp7q19f0",
  "max_comments": 200
}
```
**Response**:
```json
{
  "video_id": "9bZkp7q19f0",
  "video_title": "PSY - GANGNAM STYLE(ê°•ë‚¨ìŠ¤íƒ€ì¼) M/V",
  "total_comments_analyzed": 200,
  "toxic_count": 52,
  "normal_count": 148,
  "toxicity_percentage": 26.0,
  "top_toxic_comments": [
    {
      "comment_text": "This is the worst thing I've ever seen...",
      "author": "user123",
      "confidence": 0.967,
      "published_at": "2024-11-15T08:30:00Z",
      "comment_id": "UgxKREjvS2SBSud4BpF4AaABAg"
    }
    // ... 9 more
  ],
  "analysis_timestamp": "2024-12-11T10:40:00",
  "model_used": "distilbert"
}
```

**Formatos de URL soportados:**
- `https://www.youtube.com/watch?v=VIDEO_ID`
- `https://youtu.be/VIDEO_ID`
- `https://www.youtube.com/watch?v=VIDEO_ID&t=120s`

---

### Model Info

#### `GET /model/info`
**DescripciÃ³n**: InformaciÃ³n detallada del modelo Logistic Regression  
**Response**:
```json
{
  "model_type": "LogisticRegression",
  "threshold": 0.3,
  "vectorizer": "TF-IDF",
  "vocab_size": 8547,
  "training_samples": 1395,
  "test_accuracy": 0.525,
  "f1_score": 0.657,
  "last_updated": "2024-11-20"
}
```

---

## ğŸ’» Uso

### Ejemplos con curl

```bash
# PredicciÃ³n simple con DistilBERT
curl -X POST "https://youtube-hate-speech-detector.onrender.com/predict/transformer" \
  -H "Content-Type: application/json" \
  -d '{"text": "Your comment here"}'

# AnÃ¡lisis de video de YouTube
curl -X POST "https://youtube-hate-speech-detector.onrender.com/analyze/video" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://www.youtube.com/watch?v=9bZkp7q19f0", "max_comments": 100}'

# Health check
curl "https://youtube-hate-speech-detector.onrender.com/health"
```

### Ejemplos con Python

```python
import requests

# PredicciÃ³n con DistilBERT
response = requests.post(
    "https://youtube-hate-speech-detector.onrender.com/predict/transformer",
    json={"text": "This is an awesome video!"}
)
result = response.json()
print(f"Prediction: {result['prediction']}, Confidence: {result['confidence']}")

# AnÃ¡lisis de video
response = requests.post(
    "https://youtube-hate-speech-detector.onrender.com/analyze/video",
    json={
        "url": "https://www.youtube.com/watch?v=kJQP7kiw5Fk",
        "max_comments": 150
    }
)
analysis = response.json()
print(f"Toxicity: {analysis['toxicity_percentage']}%")
print(f"Toxic: {analysis['toxic_count']}, Normal: {analysis['normal_count']}")
```

### Frontend Local

```bash
cd frontend
npm run dev
# Abre http://localhost:5173 en tu navegador

# CaracterÃ­sticas disponibles:
# - Tab "Video Analysis": Pegar URL de YouTube
# - Tab "Text Prediction": Escribir o usar ejemplos
# - VisualizaciÃ³n de mÃ©tricas del modelo
# - Botones de ejemplo para testing rÃ¡pido
```

---

## ğŸ—ï¸ Arquitectura del Proyecto

```
ProyectX-NLP-Kiru/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py                   # FastAPI app (579 lÃ­neas, 9 endpoints)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model_loader.py           # HateSpeechDetector, DistilBERTDetector
â”‚   â”‚   â”œâ”€â”€ lr_threshold_optimized.pkl  # Modelo LR serializado
â”‚   â”‚   â””â”€â”€ distilbert-hate-speech/   # Modelo DistilBERT fine-tuned (255MB)
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ model.safetensors     # Pesos del modelo
â”‚   â”‚       â”œâ”€â”€ tokenizer_config.json
â”‚   â”‚       â””â”€â”€ vocab.txt
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ text_cleaner.py           # Pipeline NLP (tokenize, stem, clean)
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ youtube_scraper.py        # YouTubeCommentFetcher class
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx                   # Main app con tabs y mÃ©tricas
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoAnalyzer.jsx     # Componente de anÃ¡lisis de videos
â”‚   â”‚   â”‚   â””â”€â”€ TextPredictor.jsx     # Componente de predicciÃ³n de texto
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js                # Axios client (API integration)
â”‚   â”‚   â”œâ”€â”€ index.css                 # Tailwind + custom animations
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ youtoxic_english_1000.csv  # Dataset original (1000 samples)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ dataset_final_augmented.npz
â”‚       â””â”€â”€ dataset_ultra_augmented_600.npz  # 2x augmentation
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ youtoxic_hatespeech_eda.ipynb              # EDA completo
â”‚   â”œâ”€â”€ youtoxic_preprocessing_classic_models.ipynb
â”‚   â”œâ”€â”€ youtoxic_DistilBERT_augmentation_NLPAUG.ipynb  # DistilBERT training
â”‚   â””â”€â”€ youtoxic_ensemble_xgboost_data_augmentation.ipynb
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py          # 17 tests
â”‚   â”œâ”€â”€ test_model_loader.py           # 18 tests
â”‚   â”œâ”€â”€ test_api_endpoints.py          # 14 tests
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ docker-compose.yml                 # Servicios: nlp-backend, nlp-dev
â”œâ”€â”€ Dockerfile                         # Multi-stage: base + production
â”œâ”€â”€ requirements.txt                   # 25+ dependencias Python
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes                     # Git LFS para modelos grandes
â””â”€â”€ README.md
```

---

## ğŸ“Š MÃ©tricas del Modelo

### ğŸ† Modelo Principal: DistilBERT-base-uncased (Fine-tuned)

| MÃ©trica | Train/Val | Test | Overfitting |
|---------|-----------|------|-------------|
| **Accuracy** | 90.6% | **85.3%** | **5.3%** âœ… |
| **F1-Score** | - | **83.9%** | - |
| **Precision** | - | **84.6%** | - |
| **Recall** | - | **83.3%** | - |

**ConfiguraciÃ³n del Modelo:**
- **Arquitectura**: DistilBERT-base-uncased (66M parÃ¡metros)
- **Dataset**: 1,994 samples (augmented 2x)
  - Train: 1,395 samples
  - Validation: 299 samples
  - Test: 300 samples
- **Entrenamiento**:
  - Epochs: 5
  - Batch size: 16
  - Learning rate: 2e-05
  - Weight decay: 0.01
  - Max sequence length: 128 tokens
- **OptimizaciÃ³n**: AdamW optimizer
- **Framework**: PyTorch 2.0 + Transformers 4.30

### ğŸ“ˆ Modelo Baseline: Logistic Regression

| MÃ©trica | Value |
|---------|-------|
| **Accuracy** | 52.5% |
| **F1-Score** | 65.7% |
| **Precision** | 49.2% |
| **Recall (Toxic)** | 98.9% âš ï¸ |
| **Overfitting** | 23.1% âš ï¸ |

**ConfiguraciÃ³n:**
- VectorizaciÃ³n: TF-IDF (8,547 features)
- Threshold optimizado: 0.3 (prioriza recall)
- RegularizaciÃ³n: C=1.0

### ğŸ†š ComparaciÃ³n de Modelos

| Aspecto | DistilBERT | Logistic Regression |
|---------|------------|---------------------|
| **Accuracy** | â­â­â­â­â­ 85.3% | â­â­ 52.5% |
| **F1-Score** | â­â­â­â­â­ 83.9% | â­â­â­ 65.7% |
| **Overfitting** | â­â­â­â­â­ 5.3% | â­â­ 23.1% |
| **Velocidad** | â­â­â­ ~200ms | â­â­â­â­â­ ~20ms |
| **Memoria** | â­â­ 255MB | â­â­â­â­â­ ~2MB |
| **Robustez** | â­â­â­â­â­ Alta | â­â­â­ Media |

**RecomendaciÃ³n**: DistilBERT para producciÃ³n por superior accuracy, F1 y mÃ­nimo overfitting. LR Ãºtil para comparaciÃ³n y contextos con restricciones computacionales extremas.

---

## ğŸ”¬ TÃ©cnicas de NLP Aplicadas

### Preprocesamiento de Texto
1. **Lowercase conversion** - NormalizaciÃ³n a minÃºsculas
2. **URL removal** - EliminaciÃ³n de http/https links
3. **Punctuation cleaning** - RemociÃ³n de caracteres especiales
4. **Number removal** - EliminaciÃ³n de dÃ­gitos
5. **Whitespace trimming** - Limpieza de espacios extras

### TÃ©cnicas Avanzadas
1. **TokenizaciÃ³n**: `nltk.word_tokenize`
2. **Stopwords removal**: English stopwords (NLTK corpus)
3. **Stemming**: PorterStemmer para normalizaciÃ³n de palabras
4. **VectorizaciÃ³n**: TF-IDF (para LR), WordPiece Tokenizer (para DistilBERT)

### Data Augmentation (NLPAUG)
- **TÃ©cnicas**: Synonym replacement, back-translation, paraphrasing
- **Resultado**: Dataset expandido de 1,000 â†’ 1,994 samples (2x)
- **Balance de clases**: ReducciÃ³n de desbalance hate_speech/normal
- **Archivos generados**:
  - `dataset_final_augmented.npz`
  - `dataset_ultra_augmented_600.npz`

---

## ğŸ§ª Testing

### Suite Completa: 49 Tests âœ…

```bash
# Ejecutar todos los tests
pytest

# Con reporte de cobertura
pytest --cov=backend --cov-report=html

# Tests especÃ­ficos
pytest tests/test_preprocessing.py     # 17 tests
pytest tests/test_model_loader.py      # 18 tests
pytest tests/test_api_endpoints.py     # 14 tests

# Ver reporte HTML
open htmlcov/index.html
```

### Breakdown por MÃ³dulo

#### `test_preprocessing.py` (17 tests)
- âœ… Limpieza de URLs y menciones
- âœ… RemociÃ³n de puntuaciÃ³n y nÃºmeros
- âœ… TokenizaciÃ³n y stopwords
- âœ… Stemming y normalizaciÃ³n
- âœ… Pipeline completo de preprocessing

#### `test_model_loader.py` (18 tests)
- âœ… Carga de modelo Logistic Regression
- âœ… Carga de modelo DistilBERT
- âœ… Predicciones individuales y batch
- âœ… Formato de respuesta y tipos
- âœ… ComparaciÃ³n de modelos
- âœ… Manejo de errores

#### `test_api_endpoints.py` (14 tests)
- âœ… Endpoints `/`, `/health`, `/stats`, `/model/info`
- âœ… Endpoints de predicciÃ³n: `/predict`, `/predict/transformer`, `/predict/batch`
- âœ… ValidaciÃ³n de input (textos vacÃ­os, demasiado largos)
- âœ… CORS headers
- âœ… Respuestas HTTP correctas

### Cobertura
- **Backend API**: Comprehensive (endpoints, validaciÃ³n, errores)
- **Preprocessing**: Comprehensive (todas las funciones)
- **Models**: Comprehensive (carga, predicciÃ³n, comparaciÃ³n)

---

## ğŸ“ Dataset

**Fuente**: YouTube Toxic Comments Dataset (Kaggle-style)

### EstadÃ­sticas
- **Muestras originales**: 1,000 comentarios
- **Tras augmentation**: 1,994 comentarios
- **Clases**: Binario (`hate_speech` | `normal`)
- **Idioma**: InglÃ©s
- **DistribuciÃ³n**:
  - Train: 70% (1,395 samples)
  - Validation: 15% (299 samples)
  - Test: 15% (300 samples)

### Archivos de Datos
- `data/raw/youtoxic_english_1000.csv` - Dataset original
- `data/processed/dataset_final_augmented.npz` - Primera augmentation
- `data/processed/dataset_ultra_augmented_600.npz` - Augmentation 2x final

---

## ğŸ³ Docker

### Servicios

#### **nlp-backend** (ProducciÃ³n)
```bash
docker-compose up nlp-backend
```
- **Puerto**: 8000
- **Imagen**: Multi-stage optimizada
- **Health check**: AutomÃ¡tico cada 30s
- **Restart policy**: unless-stopped
- **Uso**: Deployment en Render

#### **nlp-dev** (Desarrollo)
```bash
docker-compose up nlp-dev
```
- **Puerto**: 8001
- **Hot-reload**: Activado (uvicorn --reload)
- **VolÃºmenes**: Full project mount
- **DNS**: 8.8.8.8, 8.8.4.4
- **Uso**: Desarrollo local con auto-restart

### Dockerfile Multi-Stage

**Stage 1: Base**
- Python 3.10-slim
- InstalaciÃ³n de dependencias (requirements.txt)
- Descarga de modelo Spacy (en_core_web_sm)

**Stage 2: Production**
- COPY solo archivos necesarios
- Health check endpoint configurado
- CMD: `uvicorn backend.api.main:app --host 0.0.0.0 --port 8000`

---

## ğŸš€ Deployment

### Backend en Render

**URL**: https://youtube-hate-speech-detector.onrender.com

**ConfiguraciÃ³n**:
1. Repositorio: https://github.com/Bootcamp-IA-P5/ProyectX-NLP-Kiru
2. Branch: `dev` (o `main` segÃºn rama de producciÃ³n)
3. Dockerfile: Detectado automÃ¡ticamente
4. Variables de entorno:
   - `YOUTUBE_API_KEY=tu_api_key_aqui`
5. Plan: Free tier (suficiente para demo)

**Status**: âœ… Live y funcionando

**Endpoints de VerificaciÃ³n**:
- https://youtube-hate-speech-detector.onrender.com/
- https://youtube-hate-speech-detector.onrender.com/health
- https://youtube-hate-speech-detector.onrender.com/docs

### Frontend (Local)

El frontend estÃ¡ optimizado para ejecuciÃ³n local por ahora:

```bash
cd frontend
npm install
npm run dev  # http://localhost:5173
```

**Build para producciÃ³n**:
```bash
npm run build  # Genera carpeta dist/
```

---

## ğŸ“ Notebooks de ExperimentaciÃ³n

### 1. `youtoxic_hatespeech_eda.ipynb`
**Contenido**: AnÃ¡lisis Exploratorio de Datos (EDA)
- DistribuciÃ³n de clases
- Longitud de comentarios
- Palabras mÃ¡s frecuentes (wordclouds)
- AnÃ¡lisis de balance de dataset

### 2. `youtoxic_preprocessing_classic_models.ipynb`
**Contenido**: Preprocesamiento y modelos clÃ¡sicos
- Pipeline de limpieza de texto
- VectorizaciÃ³n TF-IDF
- Modelos: Logistic Regression, SVM, Random Forest
- ComparaciÃ³n de accuracy/F1

### 3. `youtoxic_DistilBERT_augmentation_NLPAUG.ipynb`
**Contenido**: Entrenamiento de DistilBERT con augmentation â­
- Data augmentation con NLPAUG
- Fine-tuning de DistilBERT
- EvaluaciÃ³n completa (accuracy, F1, precision, recall)
- AnÃ¡lisis de overfitting
- Guardado del modelo final

### 4. `youtoxic_ensemble_xgboost_data_augmentation.ipynb`
**Contenido**: Experimentos con ensemble methods
- XGBoost classifier
- Data augmentation strategies
- Feature engineering
- ComparaciÃ³n con otros modelos

---

## ğŸ¤ ContribuciÃ³n

Este es un proyecto acadÃ©mico de **FactorÃ­a F5 - Bootcamp IA (PromociÃ³n 5)**.

### Equipo
- **Desarrollador**: Kiru
- **Rol**: Data Scientist / ML Engineer / Full-Stack Developer
- **InstituciÃ³n**: FactorÃ­a F5
- **Programa**: Bootcamp de Inteligencia Artificial

### GuÃ­a para Contribuir (Futuros Forks)
1. Fork del repositorio
2. Crear branch: `git checkout -b feature/NuevaCaracteristica`
3. Commit cambios: `git commit -m "Add: Nueva caracterÃ­stica"`
4. Push al branch: `git push origin feature/NuevaCaracteristica`
5. Abrir Pull Request

---

## ğŸ“„ Licencia

MIT License - ver archivo [LICENSE](LICENSE)

---

## ğŸ”— Enlaces Ãštiles

- **ğŸŒ API en ProducciÃ³n**: https://youtube-hate-speech-detector.onrender.com
- **ğŸ“š DocumentaciÃ³n API (Swagger)**: https://youtube-hate-speech-detector.onrender.com/docs
- **ğŸ’» Repositorio GitHub**: https://github.com/Bootcamp-IA-P5/ProyectX-NLP-Kiru
- **ğŸ¤— Hugging Face Transformers**: https://huggingface.co/transformers
- **ğŸ“º YouTube Data API**: https://developers.google.com/youtube/v3

---

## ğŸ“ Contacto

**Proyecto desarrollado como parte del Bootcamp de IA - FactorÃ­a F5**

Para consultas sobre el proyecto: [GitHub Issues](https://github.com/Bootcamp-IA-P5/ProyectX-NLP-Kiru/issues)

---

## ğŸ† Resultados y Logros

### âœ… Objetivos Cumplidos (Nivel Experto)
- âœ… **ImplementaciÃ³n de Transformers** (DistilBERT fine-tuned)
- âœ… **API REST completa** con FastAPI (9 endpoints)
- âœ… **Frontend interactivo** con React + Tailwind
- âœ… **YouTube Integration** (anÃ¡lisis de videos completos)
- âœ… **Docker containerization** (multi-stage builds)
- âœ… **Testing comprehensive** (49 tests passing)
- âœ… **Deployment en producciÃ³n** (Render)
- âœ… **Data augmentation** con NLPAUG
- âœ… **Overfitting < 10%** (5.3% achieved âœ¨)
- âœ… **Accuracy > 80%** (85.3% achieved âœ¨)

### ğŸ“ˆ MÃ©tricas Destacadas
- **85.3%** de accuracy en test set
- **83.9%** F1-score (balance precision/recall)
- **5.3%** de overfitting (excelente generalizaciÃ³n)
- **200 comentarios/video** analizados en ~3 segundos
- **49 tests** unitarios (100% passing)

### ğŸ¯ Impacto del Proyecto
Este proyecto demuestra una soluciÃ³n escalable y precisa para moderaciÃ³n automatizada de contenido en plataformas de video, con potencial de:
- Reducir costos de moderaciÃ³n manual en 70-80%
- Acelerar tiempo de respuesta de horas a segundos
- Mejorar experiencia de usuario con detecciÃ³n proactiva
- Escalar a millones de comentarios con infraestructura cloud

---

<div align="center">

â­ **Si te gusta el proyecto, dale una estrella en GitHub!** â­

<sub>Construido con â¤ï¸ usando FastAPI, DistilBERT, React y Docker</sub>

</div>
